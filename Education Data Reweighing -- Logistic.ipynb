{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff9bb68-4857-4370-a154-c2f2e21b5d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-09 23:40:13.367033: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from aif360.datasets import CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "                import load_preproc_data_adult, load_preproc_data_compas\n",
    "\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "620b3518-b207-4b25-86dc-b2347c3bcec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               instance weights features                                   \\\n",
       "                                         protected attribute                \n",
       "                                  school                 sex  age address   \n",
       "instance names                                                              \n",
       "0                           1.0      0.0                 1.0  3.0     0.0   \n",
       "1                           1.0      0.0                 1.0  2.0     0.0   \n",
       "2                           1.0      0.0                 1.0  0.0     0.0   \n",
       "3                           1.0      0.0                 1.0  0.0     0.0   \n",
       "4                           1.0      0.0                 1.0  1.0     0.0   \n",
       "...                         ...      ...                 ...  ...     ...   \n",
       "390                         1.0      1.0                 0.0  5.0     0.0   \n",
       "391                         1.0      1.0                 0.0  2.0     0.0   \n",
       "392                         1.0      1.0                 0.0  6.0     1.0   \n",
       "393                         1.0      1.0                 0.0  3.0     1.0   \n",
       "394                         1.0      1.0                 0.0  4.0     0.0   \n",
       "\n",
       "                                               ...                             \\\n",
       "                                               ...                              \n",
       "               famsize Pstatus Medu Fedu Mjob  ... famrel freetime goout Dalc   \n",
       "instance names                                 ...                              \n",
       "0                  0.0     1.0  4.0  4.0  3.0  ...    4.0      3.0   4.0  1.0   \n",
       "1                  0.0     0.0  1.0  1.0  3.0  ...    5.0      3.0   3.0  1.0   \n",
       "2                  0.0     0.0  1.0  1.0  3.0  ...    4.0      3.0   2.0  2.0   \n",
       "3                  0.0     0.0  4.0  2.0  1.0  ...    3.0      2.0   2.0  1.0   \n",
       "4                  0.0     0.0  3.0  3.0  4.0  ...    4.0      3.0   2.0  1.0   \n",
       "...                ...     ...  ...  ...  ...  ...    ...      ...   ...  ...   \n",
       "390                0.0     1.0  2.0  2.0  2.0  ...    5.0      5.0   4.0  4.0   \n",
       "391                0.0     0.0  3.0  1.0  2.0  ...    2.0      4.0   5.0  3.0   \n",
       "392                0.0     0.0  1.0  1.0  4.0  ...    5.0      5.0   3.0  3.0   \n",
       "393                0.0     0.0  3.0  2.0  2.0  ...    4.0      4.0   1.0  3.0   \n",
       "394                0.0     0.0  1.0  1.0  4.0  ...    3.0      2.0   3.0  3.0   \n",
       "\n",
       "                                                labels  \n",
       "                                                        \n",
       "               Walc health absences    G1    G2         \n",
       "instance names                                          \n",
       "0               1.0    3.0      6.0   5.0   6.0    0.0  \n",
       "1               1.0    3.0      4.0   5.0   5.0    0.0  \n",
       "2               3.0    3.0     10.0   7.0   8.0    0.0  \n",
       "3               1.0    5.0      2.0  15.0  14.0    1.0  \n",
       "4               2.0    5.0      4.0   6.0  10.0    0.0  \n",
       "...             ...    ...      ...   ...   ...    ...  \n",
       "390             5.0    4.0     11.0   9.0   9.0    0.0  \n",
       "391             4.0    2.0      3.0  14.0  16.0    1.0  \n",
       "392             3.0    3.0      3.0  10.0   8.0    0.0  \n",
       "393             4.0    5.0      0.0  11.0  12.0    0.0  \n",
       "394             3.0    5.0      5.0   8.0   9.0    0.0  \n",
       "\n",
       "[395 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import dataset\n",
    "import csv\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "dataset_used = \"/Users/a/Downloads/student+performance/student/student-mat.csv\"\n",
    "headers = \"school;sex;age;address;famsize;Pstatus;Medu;Fedu;Mjob;Fjob;reason;guardian;traveltime;studytime;failures;schoolsup;famsup;paid;activities;nursery;higher;internet;romantic;famrel;freetime;goout;Dalc;Walc;health;absences;G1;G2;G3\"\n",
    "separated_headers = headers.split(';')\n",
    "df = pd.read_csv(dataset_used, delimiter=\";\")\n",
    "d_g3 = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:1, 12:1, 13:1, 14:1, 15:1, 16:1, 17:1, 18:1, 19:1, 20:1} #convert into a binary outcome\n",
    "df['G3'] = df['G3'].map(d_g3)\n",
    "df['labels'] = df['G3']\n",
    "df = df.drop('G3', axis = 'columns')\n",
    " \n",
    "#convert categorical to numeric\n",
    "d_school = {'GP': 0, 'MS': 1}\n",
    "d_sex = {'M': 0, 'F': 1}\n",
    "d_age = {15:0, 16:1, 17:2, 18:3, 19:4, 20:5, 21:6, 22:7}\n",
    "d_address = {'U': 0, 'R': 1}\n",
    "d_famsize = {'LE3': 0, 'GT3': 0}\n",
    "d_pstatus = {'T': 0, 'A': 1}\n",
    " \n",
    "d_mjob = {'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4}\n",
    "d_fjob = {'teacher': 0, 'health': 1, 'services': 2, 'at_home': 3, 'other': 4}\n",
    "d_reason = {'home': 0, 'reputation': 1, 'course': 2, 'other': 3}\n",
    "d_guardian = {'mother': 0, 'father': 1, 'other': 2} \n",
    "\n",
    "d_schoolsup = {'yes': 0, 'no': 1}\n",
    "d_famsup = {'yes': 0, 'no': 1}\n",
    "d_paid = {'yes': 0, 'no': 1}\n",
    "d_activities = {'yes': 0, 'no': 1}\n",
    "d_nursery = {'yes': 0, 'no': 1}\n",
    "d_higher = {'yes': 0, 'no': 1}\n",
    "d_internet = {'yes': 0, 'no': 1}\n",
    "d_romantic = {'yes': 0, 'no': 1}\n",
    "#apply mappings\n",
    "df['school'] = df['school'].map(d_school)\n",
    "df['sex'] = df['sex'].map(d_sex)\n",
    "df['age'] = df['age'].map(d_age)\n",
    "df['address'] = df['address'].map(d_address)\n",
    "df['famsize'] = df['famsize'].map(d_famsize)\n",
    "df['Pstatus'] = df['Pstatus'].map(d_pstatus)\n",
    " \n",
    "df['Mjob'] = df['Mjob'].map(d_mjob)\n",
    "df['Fjob'] = df['Fjob'].map(d_fjob)\n",
    "df['reason'] = df['reason'].map(d_reason)\n",
    "df['guardian'] = df['guardian'].map(d_guardian)\n",
    " \n",
    "df['schoolsup'] = df['schoolsup'].map(d_paid)\n",
    "df['famsup'] = df['famsup'].map(d_paid)\n",
    "df['paid'] = df['paid'].map(d_paid)\n",
    "df['activities'] = df['activities'].map(d_paid)\n",
    "df['nursery'] = df['nursery'].map(d_paid)\n",
    "df['higher'] = df['higher'].map(d_paid)\n",
    "df['internet'] = df['internet'].map(d_paid)\n",
    "df['romantic'] = df['romantic'].map(d_paid)\n",
    " \n",
    "df = df.dropna()\n",
    "df = df.apply(pd.to_numeric)\n",
    "df.head()\n",
    "\n",
    "new_data = BinaryLabelDataset(favorable_label=1, unfavorable_label=0, df=df, label_names = [\"labels\"], protected_attribute_names=[\"sex\",\"romantic\"])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629fa44d-0e56-4148-b3c3-a2f378a90fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "dataset_orig = new_data\n",
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.6], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4d8a77f-125a-47e4-9e40-f868f03cdc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Dataset shape"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 32)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Favorable and unfavorable labels"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Protected attribute names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'romantic']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Privileged and unprivileged protected attribute values"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.]), array([1.])] [array([0.]), array([0.])]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Dataset feature names"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'G1', 'G2']\n"
     ]
    }
   ],
   "source": [
    "# print out some labels, names, etc.\n",
    "display(Markdown(\"#### Dataset shape\"))\n",
    "# This line uses the display function from IPython's display module and Markdown function to format the string \n",
    "#\"#### Dataset shape\" as a markdown header. This will show up as a heading in the output cell of a Jupyter notebook.\n",
    "print(dataset_orig_train.features.shape)\n",
    "#The shape is a tuple that indicates the number of instances and features in the dataset (rows, columns).\n",
    "display(Markdown(\"#### Favorable and unfavorable labels\"))\n",
    "print(dataset_orig_train.favorable_label, dataset_orig_train.unfavorable_label)\n",
    "#In the context of fairness, favorable labels might denote a positive outcome (like being granted bail),\n",
    "#while unfavorable labels might denote a negative outcome (like being denied bail)\n",
    "display(Markdown(\"#### Protected attribute names\"))\n",
    "print(dataset_orig_train.protected_attribute_names)\n",
    "#This prints the names of the protected attributes. Protected attributes are typically those that \n",
    "#should not be used for decision-making due to fairness considerations (e.g., race, gender).\n",
    "display(Markdown(\"#### Privileged and unprivileged protected attribute values\"))\n",
    "print(dataset_orig_train.privileged_protected_attributes, dataset_orig_train.unprivileged_protected_attributes)\n",
    "#This prints the values within the protected attributes that are considered privileged and unprivileged. \n",
    "#Privileged values are those that traditionally benefit from societal bias (e.g., being male in a gender attribute), \n",
    "#while unprivileged values are those that traditionally do not (e.g., being female in a gender attribute).\n",
    "display(Markdown(\"#### Dataset feature names\"))\n",
    "print(dataset_orig_train.feature_names) #features that are used to train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebe52ce-230b-429d-8884-ef65ed35f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "unprivileged_groups = [{\"sex\" : 0}]\n",
    "privileged_groups = [{\"sex\" : 1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48a26c5-8646-4458-b1a2-312dff88cd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = 0.030342\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original validation dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = 0.136951\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original test dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = 0.135948\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_orig_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "#BinaryLabelDatasetMetric is a class that provides metrics to evaluate how different the outcomes are across groups defined by protected attributes. \n",
    "#It is being used here to calculate the mean difference in outcomes.\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "\n",
    "metric_orig_valid = BinaryLabelDatasetMetric(dataset_orig_valid, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original validation dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_valid.mean_difference())\n",
    "\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dataset_orig_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original test dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())\n",
    "# the unprivileged group received less favorable outcomes compared to the privileged group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a2496a-3507-414f-b5d2-d601d8c4e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Placeholder for predicted and transformed datasets\n",
    "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "\n",
    "dataset_new_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "dataset_new_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "\n",
    "# Logistic regression classifier and predictions for training data\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "\n",
    "fav_idx = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "y_train_pred_prob = lmod.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "# Prediction probs for validation and testing data\n",
    "X_valid = scale_orig.transform(dataset_orig_valid.features)\n",
    "y_valid_pred_prob = lmod.predict_proba(X_valid)[:,fav_idx]\n",
    "\n",
    "X_test = scale_orig.transform(dataset_orig_test.features)\n",
    "y_test_pred_prob = lmod.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "class_thresh = 0.5\n",
    "dataset_orig_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_orig_valid_pred.scores = y_valid_pred_prob.reshape(-1,1)\n",
    "dataset_orig_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "y_train_pred = np.zeros_like(dataset_orig_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_orig_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_orig_train_pred.unfavorable_label\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "y_valid_pred = np.zeros_like(dataset_orig_valid_pred.labels)\n",
    "y_valid_pred[y_valid_pred_prob >= class_thresh] = dataset_orig_valid_pred.favorable_label\n",
    "y_valid_pred[~(y_valid_pred_prob >= class_thresh)] = dataset_orig_valid_pred.unfavorable_label\n",
    "dataset_orig_valid_pred.labels = y_valid_pred\n",
    "    \n",
    "y_test_pred = np.zeros_like(dataset_orig_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_orig_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_orig_test_pred.unfavorable_label\n",
    "dataset_orig_test_pred.labels = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e0eca4e-cb0f-4cdb-988d-5b98efb2f18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original-Predicted training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in GFPR between unprivileged and privileged groups\n",
      "-0.015092124630272374\n",
      "Difference in GFNR between unprivileged and privileged groups\n",
      "-0.026889888518837918\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original-Predicted validation dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in GFPR between unprivileged and privileged groups\n",
      "-0.07208559983258911\n",
      "Difference in GFNR between unprivileged and privileged groups\n",
      "0.09530245536982417\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original-Predicted testing dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in GFPR between unprivileged and privileged groups\n",
      "-0.09096284088093129\n",
      "Difference in GFNR between unprivileged and privileged groups\n",
      "0.012840522610247124\n"
     ]
    }
   ],
   "source": [
    "cm_pred_train = ClassificationMetric(dataset_orig_train, dataset_orig_train_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Predicted training dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_pred_train.difference(cm_pred_train.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_pred_train.difference(cm_pred_train.generalized_false_negative_rate))\n",
    "\n",
    "cm_pred_valid = ClassificationMetric(dataset_orig_valid, dataset_orig_valid_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Predicted validation dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_pred_valid.difference(cm_pred_valid.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_pred_valid.difference(cm_pred_valid.generalized_false_negative_rate))\n",
    "\n",
    "cm_pred_test = ClassificationMetric(dataset_orig_test, dataset_orig_test_pred,\n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original-Predicted testing dataset\"))\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_pred_test.difference(cm_pred_test.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_pred_test.difference(cm_pred_test.generalized_false_negative_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b78788-a126-4653-b2ea-2d9a4de7ee29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Accuracy before Reweighing\n",
    "original_model_lr = LogisticRegression(solver='liblinear', random_state=42)\n",
    "original_model_lr.fit(dataset_orig_train.features, dataset_orig_train.labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cd92207-3563-471a-b581-6847c7a33434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logitsic Regression Accuracy before: 0.8860759493670886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "test_pred_lr = original_model_lr.predict(dataset_orig_test.features)\n",
    "\n",
    "accuracy_before_lr = accuracy_score(dataset_orig_test.labels, test_pred_lr)\n",
    "\n",
    "print(\"Logitsic Regression Accuracy before:\", accuracy_before_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59383602-320b-4549-b2b9-e14f4bd548c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before this cell, are all models before reweighing\n",
    "## After this cell, will be the reweighing process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc21e488-8d76-4fb4-bba9-f31f9ee44ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reweighing Process.\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "reweighing = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "dataset_orig_train_rw = reweighing.fit_transform(dataset_orig_train)\n",
    "\n",
    "weights = dataset_orig_train_rw.instance_weights\n",
    "#weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "380599e0-6478-4bd9-a154-fa5dfddfe155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic After Reweighing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lr_after = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model_lr_after.fit(dataset_orig_train_rw.features, dataset_orig_train_rw.labels.ravel(), sample_weight=dataset_orig_train_rw.instance_weights)\n",
    "model_lr_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90fb4452-d419-436d-9106-ec22bf2f30fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy After Reweighing: 0.8860759493670886\n",
      "Mean difference (testing set): 0.13594771241830073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "test_pred_lr_after = model_lr_after.predict(dataset_orig_test.features)\n",
    "\n",
    "accuracy_lr_after = accuracy_score(dataset_orig_test.labels, test_pred_lr_after)\n",
    "print(\"Logistic Regression Accuracy After Reweighing:\", accuracy_lr_after)\n",
    "\n",
    "testing_metrics = BinaryLabelDatasetMetric(dataset_orig_test, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
    "print(\"Mean difference (testing set):\", testing_metrics.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41afba1-065a-4fa6-9d14-d762e2624b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
